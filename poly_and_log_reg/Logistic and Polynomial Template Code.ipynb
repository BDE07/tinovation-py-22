{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea7fbf29",
   "metadata": {},
   "source": [
    "# Logistic Regression and Polynomial Regression Template Code - 10/24/2022\n",
    "Hello everyone! This is the template code that we are going to cover/do self paced from today's Tinovation meeting (10/24/2022). We're going to be covering two new common regression models - Logistic Regression and Polynomial Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e2e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b422fe",
   "metadata": {},
   "source": [
    "# Handling the Data\n",
    "To handle the data, make sure you download the \"train.csv\" file and put it into the same folder as this file.\n",
    "\n",
    "After getting the .csv file downloaded and set up as described above, we have to load that aforementioned .csv file into a Pandas Dataframe, and plainly visualize the data to make sure that we've properly loaded the data.\n",
    "\n",
    "To do this, you will need to find the filepath of the .csv file! There are a number of ways to do this, but we've listed apt documentation for one method - this will require a little bit of problem solving.\n",
    "\n",
    "<br>\n",
    "\n",
    "Helpful commands:\n",
    "<pre>\n",
    "    os.getcwd() # --> returns the current directory as a STRING\n",
    "    os.listdir(given_path) # --> returns all directories in the given path(as a STRING) as a list\n",
    "    pandas.read_csv(filepath) # --> returns the csv file(file path is a STRING) as a pandas DataFrame\n",
    "</pre>\n",
    "If you want to read more about each, refer to following:<br>\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html <br>\n",
    "\n",
    "Hint for finding the file path:<br>\n",
    " - Maybe try looking for a certain file within a list of filenames from your current directory...do you understand why we gave you those first two commands now? ;) <br> \n",
    "   - You might have to google how to search for a certain element in a list to do the approach described above. Don't be afraid to ask for help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENTER CODE HERE (approx. 2 lines)    \n",
    "#database = ...\n",
    "#database_file = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da7b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick tests - you'll find these scattered throughout the whole code base \n",
    "assert 'database_file' in globals(), \"Didn't download the file and(or) run the code :(\"\n",
    "assert 'database' in globals(), \"Didn't initialize the database variable very sadge\"\n",
    "\n",
    "\n",
    "print(database.head()) # prints the first 10 rows of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b45cf8d",
   "metadata": {},
   "source": [
    "Now that you've successfully initialized the database and printed out the first 10 rows of the dataset, let's look at how the data seems to be oriented.\n",
    "\n",
    "We can tell from this snippet of data that there seems to be several columns of data here...but I think we can get rid of a few. There's no need to have all of these columns.\n",
    "<br>\n",
    "Which do you think are the most important - given that we're trying to find what age had the highest chance of survival?\n",
    "<br><br>\n",
    "If you said <strong>age and survival</strong>, you're correct.\n",
    "<br>\n",
    "However, there is something that I should probably warn you about. Take a look at the following column of data: \n",
    "<pre>\n",
    "Age\n",
    "    27.0\n",
    "    NaN\n",
    "    13.0\n",
    "    NaN\n",
    "    9.0\n",
    "</pre>\n",
    "<br> What does that \"NaN\" thing mean? \n",
    "- Great question! It means not a number, and usually happens when a data value is considered missing or null.\n",
    "    - If you can't see where I'm going with this...we don't want null and missing values for certain categories.\n",
    "    - We need to find a way to get rid of those rows with NaN values, so that every row in the dataset is defined.\n",
    "\n",
    "I think it would be best to try and get rid of all the other categories.<br><br>\n",
    "\n",
    "Helpful Commands:\n",
    "<pre>\n",
    "    dataset.loc[selected_rows, selected_columns] # --> returns the specified rows of the specified columns\n",
    "                                                       (as a list of the names of the rows/columns)\n",
    "                                                     \n",
    "    dataset.dropna(axis) #--> removes all the NaN(not a number) entries in the table - axis=0 means rows, axis=1 means columns\n",
    "</pre>\n",
    "If you want to read more about .loc(), look at the following: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html\n",
    "<br><br>\n",
    "Hint: We want to get all rows, but only two columns...we face two problems here.\n",
    "- We aren't going to type in every single row in a list and pass that as a parameter, we could be here for hours. Instead, use something called the slice operator, indicated with a colon in Python -->  \" : \".\n",
    "    - You might have to do some research to know how to use the slice operator to get all values. \n",
    "    - Stack Overflow to the Rescue!! https://stackoverflow.com/questions/4012340/colon-in-python-list-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fe896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENTER CODE HERE (approx. 2 lines)\n",
    "#train = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'train' in globals(), \"Didn't run the code or changed the variable name :(\"\n",
    "assert train.shape == (714, 2), f\"Shape of the new dataset should be (714, 2), but is {new_dataset.shape}\"\n",
    "\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77dcc1c",
   "metadata": {},
   "source": [
    "While data this simple doesn't really lend itself for much analysis, we'll get into much more complex datasets and do more with the datasets as we progress. For now, let's just make this simple connection. Perform any data visualization you feel would be helpful down below. (optional, but recommended!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANY DATA VIZ THAT YOU FEEL IS USEFUL CAN BE ADDED HERE! GOOGLE THE API FOR SEABORN AND GO NUTS!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7858c69e",
   "metadata": {},
   "source": [
    "We're now ready to use logistic and polynomial regression.<br><br>\n",
    "We're going to be using sci-kit learn, introduced in prior code samples(look at the linear regression code sample for reference.)\n",
    "\n",
    "Specifically, we need to do the following steps:\n",
    "- We need to first split our data into X and Y datasets (think about which is which - always ask us if you're stuck.)\n",
    "- Then we need to split that X and Y data into train and test sets - use the same thing you did get only two columns into a dataset, but this time only use 1 column in that list!\n",
    "- After that, all we have to do is fit the training data onto a logistic regression model. We do that part of the code for you.\n",
    "\n",
    "\n",
    "Helpful Commands from Scikit Learn:\n",
    "<pre>\n",
    "    train_test_split(X, y, test_size) #--> returns X_train, X_test, y_train, y_test w test_size being a ratio from 0 to 1 \n",
    "    model_name_goes_here.predict(X_test) #--> returns predictions of the data from the entered test data\n",
    "</pre>\n",
    "Hints:\n",
    "- We will provide the imports for you, and will fill in code in between.\n",
    "- Also, the test size ratio gets smaller the more total data you have - since we have a relatively small amount of data,<br>\n",
    "  we recommend a test size ratio of 0.2 -> 0.3, but feel free to experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENTER CODE HERE (approx 2 lines)\n",
    "#X = ...\n",
    "#y = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56af9d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn \n",
    "#MAKE SURE YOU HAVE SCIKIT LEARN INSTALLED!!!!\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#ENTER CODE HERE (approx. 1 line)\n",
    "#X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a02121",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'X_train' in globals(), \"Didn't run code or changed variable names\"\n",
    "assert 'y_train' in globals(), \"Didn't run code or changed variable names\"\n",
    "assert 'X_test' in globals(), \"Didn't run code or changed variable names\"\n",
    "assert 'y_test' in globals(), \"Didn't run code or changed variable names\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85fe302",
   "metadata": {},
   "source": [
    "Now that you have your X train and test, and y train and test sets, it's time to train them on the logistic regression model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#ENTER CODE HERE (approx. 1 line)\n",
    "#logpredictions = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c3bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'logpredictions' in globals(), \"Didn't run code or changed variable names\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f9dfa",
   "metadata": {},
   "source": [
    "Now, is the last part. How effective was our logistic regression? Notice how logistic regression is different from other regression models we've seen before, most notably linear regression. This will yield significantly different results than that linear regression model, and may even be a good fit! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3138ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(X_test.shape[1]*X_test.shape[0], 1)\n",
    "\n",
    "logpredictions = np.array(logpredictions).reshape(logpredictions.shape[1]*logpredictions.shape[0], 1)\n",
    "print(logpredictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8850dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[10,6])\n",
    "ax.set_title(\"Logistic Regression on Titanic Dataset\")\n",
    "ax.set_ylim(-1, 2)\n",
    "ax.scatter(X_train, y_train, color=\"black\")\n",
    "ax.plot(X_test, logpredictions, color=\"blue\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ccb194",
   "metadata": {},
   "source": [
    "It's time to train them on the polynomial regression model! This one is a little more complicated, so we'll just do the whole thing for you..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0edcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "poly = PolynomialFeatures(degree = 2, include_bias = False) #experiment with the degree!\n",
    "poly_features = poly.fit_transform(X_train.reshape(-1,1))\n",
    "\n",
    "poly_reg_model = LinearRegression()\n",
    "poly_reg_model.fit(poly_features, y_train)\n",
    "\n",
    "polypredictions = poly_reg_model.predict(poly_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd8983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'polypredictions' in globals(), \"Didn't run code or changed variable names\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78ba492",
   "metadata": {},
   "source": [
    "Now, is the last part. How effective was our polynomial regression? Notice how polynomial regression is similar to other regression models we've seen before, most notably linear regression. This will yield significantly different results than that logistic regression model, and may be a good fit or a bad fit...only way to find out is to run it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2678d27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(X_test.shape[1]*X_test.shape[0], 1)\n",
    "\n",
    "polypredictions = np.array(polypredictions).reshape(polypredictions.shape[1]*polypredictions.shape[0], 1)\n",
    "print(polypredictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[10,6])\n",
    "ax.set_title(\"Polynomial Regression on Titanic Dataset\")\n",
    "ax.set_ylim(-1, 2)\n",
    "ax.scatter(X_train, y_train, color=\"black\")\n",
    "ax.plot(X_test, polypredictions, color=\"blue\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
